python3 -m llama_cpp.server --model models/llama-2-7b/ggml-model-q4_0.gguf
